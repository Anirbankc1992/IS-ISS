{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"rtavs-wks4-2-_MokKayYong_A0214617J.ipynb","provenance":[{"file_id":"1A5fp5jGUqs1XsX-8ala-jFIO_ocKEuM_","timestamp":1594960201090},{"file_id":"1bm5fOmN3yc7xYW2fk8vS4hz97qhx9D3b","timestamp":1591246416734},{"file_id":"1aIZNOPV4RUmhiISjo4kYKB7WFdSlG2NJ","timestamp":1591159554218},{"file_id":"17edohL-PGjndRmcr6GX4uZcmFMGgKKFW","timestamp":1591149292036},{"file_id":"1F28_bWFfWm1YKp6M_C7fNwesT375uM5A","timestamp":1591084989450},{"file_id":"1Xsi1JvqWwfXQBYhvddEt8DcrupeEarAg","timestamp":1591062878649},{"file_id":"1YTxB24O5FXmKgrbi9VPkMbxFPgus6yRK","timestamp":1591001995436},{"file_id":"1UW-0VOYGKcGlqYmsJMm_ZmbUyg-BgutA","timestamp":1590741441593},{"file_id":"1RS8ieqIU8_p3Jvk0fTsYfxGFSxzjum5P","timestamp":1590721126231},{"file_id":"15E3k4QmQt21Hwu8fA0uLPFe65yaR6Q9I","timestamp":1590721014252},{"file_id":"1_P2L_rQ6K92nXW1Nsq_uOBXOascrvJ9h","timestamp":1590652109134},{"file_id":"1nJj4fl_hhFwTX4FaJeHwOKrrb1HbJmjn","timestamp":1590649579320},{"file_id":"1lokhHHLgNC39V9hfgalfA2kx6HLCd2P9","timestamp":1590635832954},{"file_id":"1CYy8i5VorhSvWN0wR1BC7_3TMNPTaZ6Y","timestamp":1590634571641},{"file_id":"1JmuiK6mE-OfrCmodTRGdtF12IhH6hX8J","timestamp":1590633831129},{"file_id":"17_lVnrVTYvjXqlr3A3Gh0IanooPRbRKc","timestamp":1590574418145},{"file_id":"1qfUV9hXrlIgs2886JqD12zcJMMHLcPcC","timestamp":1590570850319},{"file_id":"1eOlLfE_AkbpJy90ysjj60vVXuCetQOpw","timestamp":1590548226955}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"CRNVzhoo1clG"},"source":["## **1. Mount google drive**\n","---"]},{"cell_type":"code","metadata":{"id":"5W39GXyk1hME","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619794847558,"user_tz":-480,"elapsed":23976,"user":{"displayName":"Kay Yong Mok","photoUrl":"","userId":"16249806892691888971"}},"outputId":"3c813c33-cfab-4dca-ee69-673c1e967f37"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"dOQ-2xS_MYHi"},"source":["## **2. Import the libraries**\n","---"]},{"cell_type":"code","metadata":{"id":"yoi4gWDELtek","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619794929362,"user_tz":-480,"elapsed":1576,"user":{"displayName":"Kay Yong Mok","photoUrl":"","userId":"16249806892691888971"}},"outputId":"73e26fbc-055a-4023-ce46-f023ee6352e8"},"source":["import cv2\n","import sys\n","import os\n","import numpy as np\n","\n","from IPython.display import clear_output\n","from google.colab.patches import cv2_imshow\n","\n","print(\"Versions of key libraries\")\n","print(\"---\")\n","print(\"numpy:     \", np.__version__)\n","print(\"opencv    :\", cv2.__version__)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Versions of key libraries\n","---\n","numpy:      1.19.5\n","opencv    : 4.1.2\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"uaRMTv68fEIc"},"source":["## **3. Setup the classes and load the MobileNet SSD**\n","---\n"]},{"cell_type":"code","metadata":{"id":"236fltUAeHMA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619794941331,"user_tz":-480,"elapsed":5230,"user":{"displayName":"Kay Yong Mok","photoUrl":"","userId":"16249806892691888971"}},"outputId":"150001e1-c6da-4ece-ab6b-dea3d175dd67"},"source":["classNames      = {0: 'background',\n","                   1: 'aeroplane', \n","                   2: 'bicycle', \n","                   3: 'bird', \n","                   4: 'boat',\n","                   5: 'bottle', \n","                   6: 'bus', \n","                   7: 'car', \n","                   8: 'cat', \n","                   9: 'chair',\n","                   10: 'cow', \n","                   11: 'diningtable', \n","                   12: 'dog', \n","                   13: 'horse',\n","                   14: 'motorbike', \n","                   15: 'person', \n","                   16: 'pottedplant',\n","                   17: 'sheep', \n","                   18: 'sofa', \n","                   19: 'train', \n","                   20: 'tvmonitor'}\n","\n","prototxt        = '/content/gdrive/My Drive/iss/RTAVS/Week 3/data/MobileNetSSD_deploy.prototxt'\n","caffemodel      = '/content/gdrive/My Drive/iss/RTAVS/Week 3/data/MobileNetSSD_deploy.caffemodel'\n","net             = cv2.dnn.readNetFromCaffe(prototxt,\n","                                           caffemodel)\n","\n","print(\"caffemodel '\", caffemodel, \"' loaded\")"],"execution_count":3,"outputs":[{"output_type":"stream","text":["caffemodel ' /content/gdrive/My Drive/iss/RTAVS/Week 3/data/MobileNetSSD_deploy.caffemodel ' loaded\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Epqhx1ZmejSV"},"source":["## **4. Before the analysis**\n","---\n","* Step 1: Specify the video to be analyzed and its output path\n","* Step 2: Load the video. Check the frames per second (`int` and `round` must be applied since the output can be `float`). Check the width and height of each frame\n","* Step 3: Setup the codec and video writer. Note: colab so far does not support X264 or H264 encoding, so use MJPG and thus the extension of .avi for the output. No error will occur if a codec is not supported. However, there will no video file saved. \n","* Step 4: Set the threshold to determine if the identified object should be retained"]},{"cell_type":"code","metadata":{"id":"Bd5Hqsr3eq2a","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619794945187,"user_tz":-480,"elapsed":2529,"user":{"displayName":"Kay Yong Mok","photoUrl":"","userId":"16249806892691888971"}},"outputId":"8b6a9c55-ef74-4588-bd31-a8c159ff7e9f"},"source":["                                                                                # Step 1\n","videopath       = '/content/gdrive/My Drive/iss/RTAVS/Week 3/data/ff7.mp4'\n","outpath         = '/content/gdrive/My Drive/iss/RTAVS/Week4/colab/ssd_ff7.avi'\n","\n","                                                                                # Step 2\n","vs              = cv2.VideoCapture(videopath)\n","fps             = int(round(vs.get(cv2.CAP_PROP_FPS)))\n","W               = int(vs.get(cv2.CAP_PROP_FRAME_WIDTH))\n","H               = int(vs.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","\n","                                                                                # Step 3\n","fourcc          = cv2.VideoWriter_fourcc(*\"MJPG\")    \n","writer          = cv2.VideoWriter(outpath,\n","                                  fourcc,\n","                                  fps,\n","                                  (W, H),\n","                                  True)\n","\n","scoreThres      = 0.5                                                           # Step 4\n","\n","print(\"Video to be analyzed.  :\", videopath)\n","print(\"Output will be saved at:\", outpath)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Video to be analyzed.  : /content/gdrive/My Drive/iss/RTAVS/Week 3/data/ff7.mp4\n","Output will be saved at: /content/gdrive/My Drive/iss/RTAVS/Week4/colab/ssd_ff7.avi\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"P__Mxo328iRj"},"source":["## **5. Run the analysis (to be completed)**\n","---\n","* Step 1: Setup running number `fr` for reporting of the frame being analyzed\n","* Step 2: Read a frame from video stream\n","* Step 3: If there is no frame left to be analyzed, exit the while loop\n","* Step 4: Prepare the blob for `net`. Get the `rows` and `cols` of the blob. The shape of `blob` is `(1,3,300,300)`\n","* Step 5: Perform the prediction with MobileNet SSD. The shape of `pred` is `(1,1,n,7)`, `n` is the number of objects detected.\n","* Step 6: For each detected object, check its confidence score. If the score exceeds threshold, get the class and the `(x1,y1,x2,y2)` for bounding box. Re-scale the positions (relative to the size of blob, which is `(300, 300)`).\n","* Step 7: Get the actual positions of the bounding box in original frame. Express the bounding box in the form of `(x,y,w,h)`.\n","* Step 8: Setup the text to be displayed on the bounding box. Get the size of the text.\n","* Step 9: Draw the bounding box, put up the text.\n","* Step 10: Write the frame into the output\n","* Step 11: Report the amount of frames analyzed\n","* Step 12: After all frames are done, close the writer and release video stream (of the original video)"]},{"cell_type":"code","metadata":{"id":"Lo-shotn8zv-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619796512779,"user_tz":-480,"elapsed":647415,"user":{"displayName":"Kay Yong Mok","photoUrl":"","userId":"16249806892691888971"}},"outputId":"ffdbd2ae-dd95-4c15-a848-6920884fb282"},"source":["fr    = 1                                                                       # Step 1\n","\n","while True: \n","    \n","    (grabbed, frame) = vs.read()                                                # Step 2\n","\n","    if not grabbed:                                                             # Step 3\n","      break\n","\n","    output = frame.copy()\n","    blob = cv2.dnn.blobFromImage(image=cv2.resize(frame,(300,300)),             # Step 4\n","                                 scalefactor=0.007843,\n","                                 size=(300, 300),\n","                                 mean=(127.5, 127.5, 127.5),\n","                                 swapRB=False,\n","                                 crop=False)\n","    rows = blob.shape[2]\n","    cols = blob.shape[3]\n","    print(blob.shape)\n","    \n","    net.setInput(blob)                                                          # Step 5\n","    pred = net.forward()\n","    numOfObjects= pred.shape[2]\n","    print(pred.shape)\n","\n","    for i in range(numOfObjects):                                               # Step 6\n","      confidence = pred[0, 0, i, 2]\n","\n","      if confidence > scoreThres:\n","          classId = int(pred[0, 0, i, 1])\n","\n","          x1 = int(pred[0, 0, i, 3] * cols)\n","          y1 = int(pred[0, 0, i, 4] * rows)\n","          x2 = int(pred[0, 0, i, 5] * cols)\n","          y2 = int(pred[0, 0, i, 6] * rows)\n","          hFactor = H/300.0\n","          wFactor = W/300.0\n","\n","          x1 = int(wFactor*x1)                                                  # Step 7\n","          y1 = int(hFactor*y1)\n","          x2 = int(wFactor*x2)\n","          y2 = int(hFactor*y2)\n","          x = x1\n","          y = y1\n","          w = x2-x1\n","          h = y2-y1\n","\n","          txtlbl = \"{} : {:.2f}\".format(classNames[classId],                    # Step 8\n","                                        confidence)\n","          txtsize = cv2.getTextSize(txtlbl,\n","                                    cv2.FONT_HERSHEY_SIMPLEX,\n","                                    0.5,\n","                                    1)\n","          bsize = txtsize[0]\n","          bsline = txtsize[1]\n","\n","          cv2.rectangle(output,                                                 # Step 9\n","                        (x,y),\n","                        (x+w,y+h),\n","                        (0, 255, 0),\n","                        2)\n","          cv2.rectangle(output,\n","                        (x-1,y),\n","                        (x+bsize[0],y+bsize[1]+bsline),\n","                        (0, 255, 0),\n","                        -1)\n","          cv2.putText(output,\n","                      txtlbl,\n","                      (x-1,y+bsize[1]),\n","                      cv2.FONT_HERSHEY_SIMPLEX,\n","                      0.5,\n","                      (0, 0, 0),\n","                      1,\n","                      cv2.LINE_AA)\n","          \n","    if writer is None:\n","        fourcc = cv2.VideoWriter_fourcc(*\"X264\")\n","        writer = cv2.VideoWriter(outpath,\n","                                 fourcc,\n","                                 fps,\n","                                 (W, H),\n","                                 True)\n","\n","    writer.write(output)                                                        # Step 10\n","\n","    clear_output(wait=True)                                                     # Step 11\n","    if fr % 10 == 0:\n","      print(fr, \"of frames analyzed ...\")\n","\n","    fr    = fr+1\n","\n","                                                                                # Step 12\n","print(\"Closing ...\")\n","writer.release()\n","vs.release()\n","print(\"Done.\")"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Closing ...\n","Done.\n"],"name":"stdout"}]}]}