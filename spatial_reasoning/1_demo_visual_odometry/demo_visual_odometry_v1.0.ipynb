{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo: Visual odometry using single image sequence\n",
    "\n",
    "Course: NICF- Spatial Reasoning from Sensor Data (SF)\n",
    "\n",
    "Website: https://www.iss.nus.edu.sg/executive-education/course/detail/spatial-reasoning-from-sensor-data/artificial-intelligence\n",
    "\n",
    "Contact: Dr. Tian Jing\n",
    "\n",
    "Email: tianjing@nus.edu.sg\n",
    "\n",
    "## Objective\n",
    "\n",
    "- Perform visual odometry using single image sequence\n",
    "\n",
    "## Installation guideline\n",
    "- Open `Anaconda Prompt`\n",
    "\n",
    "- Append the channel `conda-forge` into your conda configuration.\n",
    "\n",
    "`conda config --append channels conda-forge`\n",
    "\n",
    "- Create a new virtual environment `srsdv` or install additional packages in your own environment\n",
    "\n",
    "**[Windows, CPU version]**\n",
    "\n",
    "`conda create -n srsdv python=3.6 numpy=1.15.1 opencv=3.4.2 matplotlib=2.2.3 tensorflow=1.12.0 scipy=1.1.0 scikit-learn=0.19.1 spyder=3.3.2 yaml=0.1.7 keras=2.2.4 pillow=5.4.1 notebook=5.7.4 pandas=0.24.2 h5py=2.8.0`\n",
    "\n",
    "**[Windows, GPU version, CUDA 9.0]**\n",
    "\n",
    "`conda create -n srsdv python=3.6 numpy=1.15.1 opencv=3.4.2 matplotlib=2.2.3 tensorflow-gpu=1.12.0 scipy=1.1.0 scikit-learn=0.19.1 spyder=3.3.2 yaml=0.1.7 keras-gpu=2.2.4 pillow=5.4.1 notebook=5.7.4 pandas=0.24.2 h5py=2.8.0`\n",
    "\n",
    "- Activate the environment `srsdv`\n",
    "\n",
    "`conda activate srsdv`\n",
    "\n",
    "- Browse to the folder that contains the workshop files, then run Jupyter Notebook\n",
    "\n",
    "`jupyter notebook`\n",
    "\n",
    "## Reference\n",
    "- Reference code: https://github.com/avisingh599/mono-vo\n",
    "- KITTI dataset, link: http://www.cvlibs.net/datasets/kitti/eval_odometry.php  \n",
    "    - \"Download odometry data set (grayscale, 22 GB)\"\n",
    "    - \"Download odometry ground truth poses (4 MB)\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CameraParameters():\n",
    "    def __init__(self, fx, fy, cx, cy):\n",
    "        self.fx = fx\n",
    "        self.fy = fy\n",
    "        self.cx = cx\n",
    "        self.cy = cy\n",
    "\n",
    "    @property\n",
    "    def camera_matrix(self):\n",
    "        matrix = np.array([[self.fx, 0.0, self.cx],\n",
    "                           [0.0, self.fx, self.cy],\n",
    "                           [0.0, 0.0, 1.0]])\n",
    "        return matrix\n",
    "\n",
    "    def __call__(self):\n",
    "        return self.camera_matrix\n",
    "\n",
    "\n",
    "class Dataset():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def image_path_left(self, index):\n",
    "        temp_path = self.image_format_left.format(index)\n",
    "        return (self.path + '/' + temp_path)\n",
    "\n",
    "    def count_image(self):\n",
    "        extension = os.path.splitext(self.image_format_left)[-1]\n",
    "        wildcard = os.path.join(self.path, '*' + extension)\n",
    "        self.image_count = len(glob.glob(wildcard))\n",
    "\n",
    "    def load_ground_truth_pose(self, gt_path):\n",
    "        ground_truth = None\n",
    "        if not os.path.exists(gt_path):\n",
    "            print(\"ground truth path is not found.\", gt_path)\n",
    "            return None\n",
    "\n",
    "        ground_truth = []\n",
    "\n",
    "        with open(gt_path) as gt_file:\n",
    "            gt_lines = gt_file.readlines()\n",
    "\n",
    "            for gt_line in gt_lines:\n",
    "                pose = self.convert_text_to_ground_truth(gt_line)\n",
    "                ground_truth.append(pose)\n",
    "        return ground_truth\n",
    "\n",
    "    def convert_text_to_ground_truth(self, gt_line):\n",
    "        pass\n",
    "\n",
    "                \n",
    "class KittiDataset(Dataset):\n",
    "    def __init__(self, path):\n",
    "        self.image_format_left = '{:06d}.png'\n",
    "        self.path = os.path.join(path, 'image_0')\n",
    "        self.calibfile = os.path.join(path, 'calib.txt')\n",
    "        sequence_count = os.path.dirname(self.path).split('/')[-1]\n",
    "\n",
    "        gt_path = os.path.join(path, sequence_count + '.txt')\n",
    "\n",
    "        self.count_image()\n",
    "        self.ground_truth = self.load_ground_truth_pose(gt_path)\n",
    "        self.camera_matrix = self.load_camera_parameters(self.calibfile)\n",
    "\n",
    "    def convert_text_to_ground_truth(self, gt_line):\n",
    "        matrix = np.array(gt_line.split()).reshape((3, 4)).astype(np.float32)\n",
    "        return matrix\n",
    "\n",
    "    def load_camera_parameters(self, calibfile):\n",
    "        if not os.path.exists(calibfile):\n",
    "            print(\"camera parameter file path is not found.\", calibfile)\n",
    "            return None\n",
    "\n",
    "        with open(calibfile, 'r') as f:\n",
    "            line = f.readline()\n",
    "            part = line.split()\n",
    "            param = CameraParameters(float(part[1]), float(part[6]),\n",
    "                                     float(part[3]), float(part[7]))\n",
    "\n",
    "            return param\n",
    "\n",
    "\n",
    "dataset_dict = {'kitti': KittiDataset}\n",
    "\n",
    "\n",
    "def create_dataset(options):\n",
    "    return dataset_dict[options.dataset](options.path)\n",
    "\n",
    "def calc_euclid_dist(p1, p2):\n",
    "    a = math.pow((p1[0] - p2[0]), 2.0) + math.pow((p1[1] - p2[1]), 2.0)\n",
    "    return math.sqrt(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class options:\n",
    "    dataset = 'kitti'\n",
    "    path = 'data/00/'\n",
    "    \n",
    "dataset = create_dataset(options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1001 images in the dataset.\n"
     ]
    }
   ],
   "source": [
    "feature_detector = cv2.FastFeatureDetector_create(threshold=25, nonmaxSuppression=True)\n",
    "\n",
    "lk_params = dict(winSize=(21, 21), criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 30, 0.03))\n",
    "\n",
    "current_pos = np.zeros((3, 1))\n",
    "current_rot = np.eye(3)\n",
    "\n",
    "print(\"There are %d images in the dataset.\" % (dataset.image_count))\n",
    "\n",
    "prev_image = None\n",
    "\n",
    "valid_ground_truth = False\n",
    "if dataset.ground_truth is not None:\n",
    "    valid_ground_truth = True\n",
    "\n",
    "if dataset.camera_matrix is not None:\n",
    "    camera_matrix = dataset.camera_matrix()\n",
    "else:\n",
    "    camera_matrix = np.array([[718.8560, 0.0, 607.1928],\n",
    "                              [0.0, 718.8560, 185.2157],\n",
    "                              [0.0, 0.0, 1.0]])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAADsCAYAAAB0bdFQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAEpNJREFUeJzt3X+s3XV9x/HnixZSxBV/3KvDXkjRFQOJBvUEXSbqhkJt3MBly2gAZWNrNINkyHSYYcLALZtmujkRAwZQFEkzf3ATwasu4PZHTXpqoVC0szQMblvn9VeGAa3Ae3+cT+3xevWe+7u3Ph/JN+d8v9/P+ZzP58PhvO738/2eflNVSJJ01FI3QJJ0eDAQJEmAgSBJagwESRJgIEiSGgNBkgQYCJKkxkCQJAEGgiSpWbnUDZiJoaGhWrt27VI3Q5KWjaGhIcbGxsaqav10ZZdVIKxdu5Zut7vUzZCkZSXJ0CDlnDKSJAEGgiSpMRAkSYCBIElqDARJEmAgSJIaA0GSBBgIkqTGQJAkAQaCJKkxECRJgIEgSWoMBEkSYCBIkhoDQZIEGAiSpMZAkCQBBoIkqTEQJEmAgSBJagYKhCTrk+xKsjvJlVPsPynJ3Um2J9mRZEPbfkGSe/uWp5Oc3va9Isn9rc4PJcn8dk2SNBPTBkKSFcB1wBuB04CNSU6bVOwqYHNVvQw4H/gIQFV9qqpOr6rTgYuAh6vq3vaa64FNwLq2rJ+H/kiSZmmQI4QzgN1VtaeqDgC3A+dOKlPA6vb8eGDfFPVsBD4NkOQEYHVVbamqAj4BnDeL9kuS5snKAcqsAR7tWx8HXjmpzNXAl5JcBhwHvH6Kev6EQ0GyptXTX+eaAdoiSVoggxwhTDW3X5PWNwK3VNUIsAG4NcnP6k7ySuDxqnpgBnUefO2mJN0k3YmJiQGaK0majUECYRw4sW99hF+cEroE2AxQVVuAVcBQ3/7zadNFfXWOTFMnrb4bqqpTVZ3h4eEBmitJmo1BAmErsC7JyUmOofflPjqpzCPAWQBJTqUXCBNt/Sjgj+mdewCgqvYDjyV5Vbu66C3AHXPsiyRpDqYNhKp6ErgUGAO+Qe9qop1JrknyB63YFcBfJLmP3pHAxe1kMcBrgPGq2jOp6rcDHwN2Aw8Bd825N5KkWcuh7+3DX6fTqW63u9TNkKRlJcm2qupMV85fKkuSAANBktQYCJIkwECQJDUGgiQJMBAkSY2BIEkCDARJUmMgSJIAA0GS1BgIkiTAQJAkNQaCJAkwECRJjYEgSQIMBElSYyBIkgADQZLUGAiSJMBAkCQ1BoIkCTAQJEmNgSBJAgwESVJjIEiSgAEDIcn6JLuS7E5y5RT7T0pyd5LtSXYk2dC376VJtiTZmeT+JKva9ntanfe25Xnz1y1J0kytnK5AkhXAdcAbgHFga5LRqnqwr9hVwOaquj7JacCdwNokK4FPAhdV1X1Jngv8tO91F1RVd746I0mavUGOEM4AdlfVnqo6ANwOnDupTAGr2/PjgX3t+dnAjqq6D6CqvldVT8292ZKk+TZIIKwBHu1bH2/b+l0NXJhknN7RwWVt+ylAJRlL8vUk75r0upvbdNF7kmSqN0+yKUk3SXdiYmKA5kqSZmOQQJjqi7omrW8EbqmqEWADcGuSo+hNSb0auKA9vjnJWe01F1TVS4Az23LRVG9eVTdUVaeqOsPDwwM0V5I0G4MEwjhwYt/6CIemhA66BNgMUFVbgFXAUHvtV6vqu1X1OL2jh5e3cnvb42PAbfSmpiRJS2SQQNgKrEtycpJjgPOB0UllHgHOAkhyKr1AmADGgJcmeUY7wfxa4MEkK5MMtfJHA28CHpiPDkmSZmfaq4yq6skkl9L7cl8B3FRVO5NcA3SrahS4ArgxyeX0ppMurqoCfpDkA/RCpYA7q+oLSY4DxloYrAC+Aty4EB2UJA0mve/t5aHT6VS361WqkjQTSbZVVWe6cv5SWZIEGAiSpMZAkCQBBoIkqTEQJEmAgSBJagwESRJgIEiSGgNBkgQYCJKkxkCQJAEGgiSpMRAkSYCBIElqDARJEmAgSJIaA0GSBBgIkqTGQJAkAQaCJKkxECRJgIEgSWoMBEkSYCBIkpqBAiHJ+iS7kuxOcuUU+09KcneS7Ul2JNnQt++lSbYk2Znk/iSr2vZXtPXdST6UJPPXLUnSTK2crkCSFcB1wBuAcWBrktGqerCv2FXA5qq6PslpwJ3A2iQrgU8CF1XVfUmeC/y0veZ6YBPwtVZ+PXDXPPVLkpa1z2/fy/vHdrHvh0/wgmcdyzvPeTHnvWzNgr7nIEcIZwC7q2pPVR0AbgfOnVSmgNXt+fHAvvb8bGBHVd0HUFXfq6qnkpwArK6qLVVVwCeA8+bYF0k6Inx++17e/dn72fvDJyhg7w+f4N2fvZ/Pb9+7oO87SCCsAR7tWx9v2/pdDVyYZJzeX/uXte2nAJVkLMnXk7yrr87xaeoEIMmmJN0k3YmJiQGaK0nL2/vHdvHET5/6uW1P/PQp3j+2a0Hfd5BAmGpuvyatbwRuqaoRYANwa5Kj6E1JvRq4oD2+OclZA9bZ21h1Q1V1qqozPDw8QHMlaXnb98MnZrR9vgwSCOPAiX3rIxyaEjroEmAzQFVtAVYBQ+21X62q71bV4/SOHl7eto9MU6ck/Vp6wbOOndH2+TJIIGwF1iU5OckxwPnA6KQyjwBnASQ5lV4gTABjwEuTPKOdYH4t8GBV7QceS/KqdnXRW4A75qVHkrTMvfOcF3Ps0St+btuxR6/gnee8eEHfd9qrjKrqySSX0vtyXwHcVFU7k1wDdKtqFLgCuDHJ5fSmfi5uJ4t/kOQD9EKlgDur6gut6rcDtwDH0ru6yCuMJAl+djXRYl9llN739vLQ6XSq2+0udTMkaVlJsq2qOtOV85fKR5r9++FFL4Jvf3upWyJpmTEQjjTXXgsPP9x7lKQZMBCOJPv3w803w9NP9x49SpA0AwbCkeTaa3thAPDUUx4lSJoRA+FIcfDo4MCB3vqBAx4lSJoRA+FI0X90cJBHCZJmwEA4UoyOHjo6OOjAAbjD3/tJGsy0P0zTMjE+Pn0ZSfoVPEKQJAEGgiSpMRAkSYCBIElqDARJEmAgSJIaA0GSBBgIkqTGQJAkAQaCJKkxECRJgIEgSWoMBEkSYCBIkhoDQZIEGAiSpGagQEiyPsmuJLuTXDnF/pOS3J1ke5IdSTa07WuTPJHk3rZ8tO8197Q6D+573vx1S5I0U9PeMS3JCuA64A3AOLA1yWhVPdhX7Cpgc1Vdn+Q04E5gbdv3UFWd/kuqv6CqurNuvSRp3gxyhHAGsLuq9lTVAeB24NxJZQpY3Z4fD+ybvyZKkhbDIIGwBni0b328bet3NXBhknF6RweX9e07uU0lfTXJmZNed3ObLnpPksyw7ZKkeTRIIEz1RV2T1jcCt1TVCLABuDXJUcB+4KSqehnwDuC2JAePJC6oqpcAZ7bloinfPNmUpJukOzExMUBzJUmzMUggjAMn9q2P8ItTQpcAmwGqaguwChiqqp9U1ffa9m3AQ8ApbX1ve3wMuI3e1NQvqKobqqpTVZ3h4eFB+yVJmqFBAmErsC7JyUmOAc4HRieVeQQ4CyDJqfQCYSLJcDspTZIXAuuAPUlWJhlq248G3gQ8MB8dkiTNzrRXGVXVk0kuBcaAFcBNVbUzyTVAt6pGgSuAG5NcTm866eKqqiSvAa5J8iTwFPC2qvp+kuOAsRYGK4CvADcuSA8lSQNJ1eTTAYevTqdT3a5XqUrSTCTZVlWd6cr5S2VJEmAgSJIaA0GSBBgIkqTGQJAkAQaCJKkxECRJgIEgSWoMBEkSYCBIkhoDQZIEGAiSpMZAkCQBBoIkqTEQJEmAgSBJagwESRJgIEiSGgNBkgQYCJKkxkCQJAEGgiSpMRAkSYCBIElqBgqEJOuT7EqyO8mVU+w/KcndSbYn2ZFkQ9u+NskTSe5ty0f7XvOKJPe3Oj+UJPPXLUnSTE0bCElWANcBbwROAzYmOW1SsauAzVX1MuB84CN9+x6qqtPb8ra+7dcDm4B1bVk/+25IkuZqkCOEM4DdVbWnqg4AtwPnTipTwOr2/Hhg36+qMMkJwOqq2lJVBXwCOG9GLZckzatBAmEN8Gjf+njb1u9q4MIk48CdwGV9+05uU0lfTXJmX53j09QpSVpEgwTCVHP7NWl9I3BLVY0AG4BbkxwF7AdOalNJ7wBuS7J6wDp7b55sStJN0p2YmBiguZKk2RgkEMaBE/vWR/jFKaFLgM0AVbUFWAUMVdVPqup7bfs24CHglFbnyDR10l53Q1V1qqozPDw8QHMlSbMxSCBsBdYlOTnJMfROGo9OKvMIcBZAklPpBcJEkuF2UpokL6R38nhPVe0HHkvyqnZ10VuAO+alR5KkWVk5XYGqejLJpcAYsAK4qap2JrkG6FbVKHAFcGOSy+lN/VxcVZXkNcA1SZ4EngLeVlXfb1W/HbgFOBa4qy2SpCWS3kU+y0On06lut7vUzZCkZSXJtqrqTFfOXypLkgADQZLUGAiSJMBAkCQ1BoIkCTAQJEmNgSBJAgwESVJjIEiSAANBktQYCJIkwECQJDUGgiQJMBAkSY2BIEkCDARJUmMgSJIAA0GS1BgIkiTAQJAkNQaCJAkwECRJjYEgSQIMBElSYyBIkoABAyHJ+iS7kuxOcuUU+09KcneS7Ul2JNkwxf4fJfnrvm0PJ7k/yb1JunPviiRpLlZOVyDJCuA64A3AOLA1yWhVPdhX7Cpgc1Vdn+Q04E5gbd/+DwJ3TVH971bVd2fbeEnS/BnkCOEMYHdV7amqA8DtwLmTyhSwuj0/Hth3cEeS84A9wM65N1eStFAGCYQ1wKN96+NtW7+rgQuTjNM7OrgMIMlxwN8AfzdFvQV8Kcm2JJt+2Zsn2ZSkm6Q7MTExQHMlSbMxSCBkim01aX0jcEtVjQAbgFuTHEUvCD5YVT+aoo7fqaqXA28E/jLJa6Z686q6oao6VdUZHh4eoLmSpNmY9hwCvSOCE/vWR+ibEmouAdYDVNWWJKuAIeCVwB8leR/wLODpJD+uqg9X1b5W/jtJPkdvauo/59QbSdKsDXKEsBVYl+TkJMcA5wOjk8o8ApwFkORUYBUwUVVnVtXaqloL/AvwD1X14STHJfmNVv444GzggXnpkSRpVqY9QqiqJ5NcCowBK4CbqmpnkmuAblWNAlcANya5nN500sVVNXlaqd/zgc8lOdiG26rqi3PsiyRpDvKrv7cPL51Op7pdf7IgSTORZFtVdaYr5y+VJUmAgSBJagwESRJgIEiSmmV1UjnJBPA/S92OBTAE+G86OQ79HIsex+GQ2Y7FdwGqav10BZdVIBypknQHuQLgSOc4HOJY9DgOhyzGWDhlJEkCDARJUmMgHB5uWOoGHCYch0Mcix7H4ZAFHwvPIUiSAI8QJEmNgbBIkjwnyZeTfKs9PvuXlHtrK/OtJG/t235Pu6/1vW153uK1fv7MdRz69o8mWdb/Qu48fCa+mOS+JDuTfLTd7nbZmcs4JHlGki8k+WYbh39c3NbPn3n4PPx9kkeTTHX/mcFUlcsiLMD7gCvb8yuBf5qizHPo3W70OcCz2/Nnt333AJ2l7sdSj0Pb/4fAbcADS92fJf5MrG6PAT4DnL/UfVrscQCeQe/e7ADHAP8FvHGp+7REn4dXAScAP5ptGzxCWDznAh9vzz8OnDdFmXOAL1fV96vqB8CXaTceOoLMaRySPBN4B/DeRWjrQpvTWFTV/7UyK+l9GS7XE4KzHoeqeryq7gao3j3fv07vJl7L0Vw/D1+rqv1zaYCBsHief/A/VnucaspnuvtX39ymi96TdjOJZWiu43At8M/A4wvZyEUy589EkjHgO8BjwL8vXFMX1Hz8v0GSZwG/D/zHArVzoc3LOMzFILfQ1ICSfAX4zSl2/e2gVUyx7eBffRdU1d52p7nPABcBn5h5KxfeQo1DktOB36qqy5OsnWXzFtUCfyaoqnPaLWs/Bfwevb8YDzsLPQ5JVgKfBj5UVXtm3sLFsdDjMFcGwjyqqtf/sn1J/jfJCVW1P8kJ9P6qm2wceF3f+gi9cwdU1d72+FiS2+jdg/qwDIQFHIffBl6R5GF6n93nJbmnql7HYWohPxN97/HjJKP0phwOy0BYhHG4AfhWVf3LPDR3wSzG52EunDJaPKPAwSsC3grcMUWZMeDsJM9uVxicDYwlWZlkCCDJ0cCbWL73oJ71OFTV9VX1gurdo/vVwH8fzmEwgLl8Jp7ZvjQO/nW8AfjmIrR5Icx6HACSvBc4HvirRWjrQprTOMyLpT6z/uuyAM+lN7f5rfb4nLa9A3ysr9yfAbvb8qdt23HANmAHsBP4V2DFUvdpscdhUj1rWf5XGc3lM/F8YGvfZ+LfgJVL3aclGIcRelMm3wDubcufL3WfFnsc2vb30TuCeLo9Xj3TNvhLZUkS4JSRJKkxECRJgIEgSWoMBEkSYCBIkhoDQZIEGAiSpMZAkCQB8P/Tq19q9rcEmAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "position_figure = plt.figure()\n",
    "position_axes = position_figure.add_subplot(1, 1, 1)\n",
    "frame_index_list = []\n",
    "position_axes.set_aspect('equal', adjustable='box')\n",
    "\n",
    "\n",
    "for index in range(dataset.image_count):\n",
    "    # load image\n",
    "    if not os.path.exists(dataset.image_path_left(index)):\n",
    "        continue\n",
    "        \n",
    "    image = cv2.imread(dataset.image_path_left(index))\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # main process\n",
    "    keypoint = feature_detector.detect(image, None)\n",
    "\n",
    "    if prev_image is None:\n",
    "        prev_image = image\n",
    "        prev_keypoint = keypoint\n",
    "        continue\n",
    "\n",
    "    points = np.array(list(map(lambda x: [x.pt], prev_keypoint)),dtype=np.float32)\n",
    "\n",
    "    p1, st, err = cv2.calcOpticalFlowPyrLK(prev_image,image, points, None, **lk_params)\n",
    "\n",
    "    E, mask = cv2.findEssentialMat(p1, points, camera_matrix, cv2.RANSAC, 0.999, 1.0, None)\n",
    "\n",
    "    points, R, t, mask = cv2.recoverPose(E, p1, points, camera_matrix)\n",
    "\n",
    "    scale = 1.0\n",
    "\n",
    "    # calc scale from ground truth if exists.\n",
    "    if valid_ground_truth:\n",
    "        ground_truth = dataset.ground_truth[index]\n",
    "        ground_truth_pos = [ground_truth[0, 3], ground_truth[2, 3]]\n",
    "        previous_ground_truth = dataset.ground_truth[index - 1]\n",
    "        previous_ground_truth_pos = [\n",
    "            previous_ground_truth[0, 3],\n",
    "            previous_ground_truth[2, 3]]\n",
    "\n",
    "        scale = calc_euclid_dist(ground_truth_pos,\n",
    "                                 previous_ground_truth_pos)\n",
    "\n",
    "    current_pos += current_rot.dot(t) * scale\n",
    "    current_rot = R.dot(current_rot)\n",
    "\n",
    "    # get ground truth if eist.\n",
    "    if valid_ground_truth:\n",
    "        ground_truth = dataset.ground_truth[index]\n",
    "        position_axes.scatter(ground_truth[0, 3], ground_truth[2, 3], marker='^', c='r')\n",
    "\n",
    "    # calc rotation error with ground truth.\n",
    "    if valid_ground_truth:\n",
    "        ground_truth = dataset.ground_truth[index]\n",
    "        ground_truth_rotation = ground_truth[0: 3, 0: 3]\n",
    "        r_vec, _ = cv2.Rodrigues(current_rot.dot(ground_truth_rotation.T))\n",
    "        #rotation_error = np.linalg.norm(r_vec)\n",
    "        frame_index_list.append(index)\n",
    "        #rotation_error_list.append(rotation_error)\n",
    "\n",
    "    position_axes.scatter(current_pos[0][0], current_pos[2][0])\n",
    "    plt.pause(.01)\n",
    "\n",
    "    img = cv2.drawKeypoints(image, keypoint, None)\n",
    "    cv2.putText(img, dataset.image_path_left(index), (20,30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "    \n",
    "    cv2.imshow('Input frames with features (Press ESC to exit). Results are saved as position_plot.png', img)\n",
    "    if cv2.waitKey(1) == 27:\n",
    "        break\n",
    "\n",
    "    prev_image = image\n",
    "    prev_keypoint = keypoint\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "position_figure.savefig(\"position_plot.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Have a nice day!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
